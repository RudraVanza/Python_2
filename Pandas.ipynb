{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                                Chap 1 :- Pandas\n",
    "                \n",
    "                \n",
    "# ➡ Pandas Series(1D):- \n",
    "        1> Tuple()\n",
    "        2> Dictionary{}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1> Tuple\n",
    "import pandas as pd\n",
    "a = (1,7,2,5)\n",
    "s = pd.Series(a)\n",
    "# s = pd.Series(a,index = ['x','y','z','w'])      # For Index from x,y,z,w\n",
    "print(s)\n",
    "print(s[0])\n",
    "print(s[1])\n",
    "print(s[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2> Dictionary\n",
    "data = {\"day1\" : 420,\"day2\":390,\"day3\":330}\n",
    "s = pd.Series(data)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ➡ Data Frame(2D) :- \n",
    "        1> by using dictionary\n",
    "        2> by using CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1> by using dictionary\n",
    "data = {\"A\":[1,2,4],\"B\":[5,6,8],\"C\":[9,7,5]}\n",
    "df = pd.DataFrame(data)\n",
    "df # OR ➡ print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"B\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"B\",\"C\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"B\",\"C\"]].loc[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2> By using CSV File\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"auto-mpg.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()    #for get Information of csv file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()  #default : First 5 line of csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(9)   #First 5 line of csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()        #default : Last 5 line of csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(7)    #First 7 line of csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"model year\",\"origin\",\"car name\"]].loc[101:110]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ➡                                                  DATA CLEANING\n",
    "    1> DATA DROP\n",
    "    2> FILL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "data = {\"name\":[\"william\",\"Emma\",\"Sofia\",\"Markus\",\"Eward\",\"Thomas\",\"Ethan\",np.nan,\"Arun\",\"Ankita\",\"Paula\"],\"region\":[np.nan,\"north\",\"east\",np.nan,\"west\",\"west\",\"south\",np.nan,\"west\",\"east\",\"south\"],\"sales\":[50000,50000,np.nan,np.nan,42000,72000,49000,np.nan,67000,65000,67000],\"expences\":[42000,43000,np.nan,np.nan,38000,39000,42000,np.nan,39000,50000,45000]}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1> DATA DROP\n",
    "                                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()  #isna() for check null data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(thresh = 2)       #dropna() dor remove null data, thresh = 2 means every column have atlist 2 valid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna()  # remove all row with any number of null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove only if all values are null\n",
    "df.dropna(how = \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop only seles and expences are null \n",
    "df.dropna(subset = [\"sales\",\"expences\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis = 0)  #same as dropna() , axis = 0 means X axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis = 1) #same as dropna() , axis = 1 means Y axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sales\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2> FILL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sales\"].fillna(0)  #replace all null value of Sales column with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sales\"].fillna(df[\"sales\"].mean())  #replace all null value of Sales column with avg of sales column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sales\"].fillna(df[\"sales\"].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"auto-mpg.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"horsepower\"]==\"?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"mpg\"]>35]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   MIMP Progrem\n",
    "\n",
    "#   Finding and Removing Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIND outliers\n",
    "# STEP 1\n",
    "q1 = df[\"acceleration\"].quantile(0.25)\n",
    "q3 = df[\"acceleration\"].quantile(0.75)\n",
    "# STEP 2\n",
    "iqr = q3-q1\n",
    "# STEP 3\n",
    "low = q1 - (1.5*iqr)\n",
    "high = q3 + (1.5*iqr)\n",
    "print(\"Q1 :- \",q1)\n",
    "print(\"Q3 :- \",q3)\n",
    "print(\"IQR :- \",iqr)\n",
    "print(\"LOW :- \",low)\n",
    "print(\"HIGH :- \",high)\n",
    "# Finding outliers\n",
    "outliers = df[(df[\"acceleration\"]<low) | (df[\"acceleration\"]>high)]\n",
    "outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove outliers\n",
    "# STEP 1\n",
    "q1 = df[\"acceleration\"].quantile(0.25)\n",
    "q3 = df[\"acceleration\"].quantile(0.75)\n",
    "# STEP 2\n",
    "iqr = q3-q1\n",
    "# STEP 3\n",
    "low = q1 - (1.5*iqr)\n",
    "high = q3 + (1.5*iqr)\n",
    "print(\"Q1 :- \",q1)\n",
    "print(\"Q3 :- \",q3)\n",
    "print(\"IQR :- \",iqr)\n",
    "print(\"LOW :- \",low)\n",
    "print(\"HIGH :- \",high)\n",
    "# removing outliers\n",
    "outliers = df[(df[\"acceleration\"]>=low) & (df[\"acceleration\"]<=high)]\n",
    "outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"diabetes_unclean.csv\")\n",
    "# STEP 1\n",
    "q1 = df[\"HbA1c\"].quantile(0.25)\n",
    "q3 = df[\"HbA1c\"].quantile(0.75)\n",
    "# STEP 2\n",
    "iqr = q3-q1\n",
    "# STEP 3\n",
    "low = q1 - (1.5*iqr)\n",
    "high = q3 + (1.5*iqr)\n",
    "print(\"Q1 :- \",q1)\n",
    "print(\"Q3 :- \",q3)\n",
    "print(\"IQR :- \",iqr)\n",
    "print(\"LOW :- \",low)\n",
    "print(\"HIGH :- \",high)\n",
    "# Finding outliers\n",
    "outliers = df[(df[\"HbA1c\"]<low) | (df[\"HbA1c\"]>high)]\n",
    "outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"diabetes_unclean.csv\")\n",
    "# STEP 1\n",
    "q1 = df[\"HbA1c\"].quantile(0.25)\n",
    "q3 = df[\"HbA1c\"].quantile(0.75)\n",
    "# STEP 2\n",
    "iqr = q3-q1\n",
    "# STEP 3\n",
    "low = q1 - (1.5*iqr)\n",
    "high = q3 + (1.5*iqr)\n",
    "print(\"Q1 :- \",q1)\n",
    "print(\"Q3 :- \",q3)\n",
    "print(\"IQR :- \",iqr)\n",
    "print(\"LOW :- \",low)\n",
    "print(\"HIGH :- \",high)\n",
    "# Removing outliers\n",
    "outliers = df[(df[\"HbA1c\"]>=low) & (df[\"HbA1c\"]<=high)]\n",
    "outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# drop duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = {\"A\":[\"Team-A\",\"Team-B\",\"Team-B\",\"Team-C\",\"Team-A\"],\"B\":[50,40,40,30,50],\"C\":[True,False,False,False,True]}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates() #To Remove Duplicate row in table\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"auto-mpg.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()  #To get info about table , horsepower has null that's why i will not include in below table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all') #go get all column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr() # To get co-relation between every column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scatter Matrix / Pair Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "pd.plotting.scatter_matrix(df,figsize=[15,15],marker=\"v\",alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qualititative Data vs Quantitative Data (only theory no practical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallel Cordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import parallel_coordinates as pc\n",
    "pl = pc(df,'origin',cols=[\"mpg\",\"mpg\"],color=['red','blue','black'])\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Tebulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"auto-mpg.csv\")\n",
    "pd.crosstab(df['cylinders'],df['model year'],rownames=['cylinders'],colnames=['model year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QB 16\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df=pd.DataFrame([[0,1.0,2.0,np.nan,5],[2.0,0,1.0,5.0,np.nan],[5.0,0,1.0,np.nan,5.0]])\n",
    "df.dropna()\n",
    "print(df.loc[1,3])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QB 30\n",
    "df = pd.read_csv(\"auto-mpg.csv\")\n",
    "df = df.drop([\"mpg\",\"cylinders\"],axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qb 31\n",
    "# 1\n",
    "df = pd.read_csv(\"D:\\Rudra_vanza\\CSV\\heights_weights.csv\")\n",
    "df\n",
    "# 2\n",
    "# df.info()\n",
    "# 3\n",
    "# df.describe()\n",
    "# 4\n",
    "# df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
